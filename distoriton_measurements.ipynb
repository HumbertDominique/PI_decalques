{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f3756d",
   "metadata": {},
   "source": [
    "# Radial distortion measurement\n",
    "\n",
    "02.06.2025 - Dominique Humbert\n",
    "Initial version: heavily inspired by Discorpy's documentation (https://discorpy.readthedocs.io)\n",
    "\n",
    "Make sure the preferred method and the other give the same values (there is a mistake somewhere)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf6d32b",
   "metadata": {},
   "source": [
    "## User manual\n",
    "\n",
    "### Dot detection mode\n",
    "1. Fill in the inputs\n",
    "2. Image a grid of dots. The more the better for the fitting. ISO 9030, ISO 17850 calls for at least 15 dots in height or width of the image.\n",
    "3. Image a line of dots with one in the center of the FoV for the measurement. ISO 9030, ISO 17850 calls for at least 15 dots in height or width of the image.\n",
    "4. Run the code\n",
    " \n",
    " ### Dot prediction mode\n",
    "\n",
    "Preferred method\n",
    "\n",
    "1. Fill in the inputs\n",
    "2. Image a grid of dots. The more the better for the fitting. ISO 9030, ISO 17850 calls for at least 15 dots in height or width of the image.\n",
    "3. Input theoretical coordinate into the forward model to get the distorted position and compute the distortion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d03d1a9",
   "metadata": {},
   "source": [
    "## Input parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82668c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_path = r\"measurments/dot.jpg\"\n",
    "distortion_measurment_path = r\"measurments/dot1.jpg\"    # image patht thi the line of dots\n",
    "outputs_path = r\"outputs\"                               # Output folder\n",
    "poly_coef = 5                                           # Number of polynomial coefficients\n",
    "image_fov_y = 2056   # Complete FoV in px\n",
    "image_fov_x = 2464   # Complete FoV in px\n",
    "\n",
    "\n",
    "INVERT = True   # True if black dots on white bcg\n",
    "\n",
    "PREFERRED_METHOD = False\n",
    "preferred_method_dots = 10  # N points at which to compute the distotions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f0db51",
   "metadata": {},
   "source": [
    "## Computing the radial distortion coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import discorpy.util.utility as utils\n",
    "import discorpy.losa.loadersaver as losa\n",
    "import discorpy.prep.preprocessing as prep\n",
    "import discorpy.proc.processing as proc\n",
    "import discorpy.post.postprocessing as post\n",
    "\n",
    "mat0 = losa.load_image(calibration_path) # Load image\n",
    "(height, width) = mat0.shape\n",
    "\n",
    "mat1 = prep.binarization(mat0)\n",
    "# Calculate the median dot size and distance between them.\n",
    "(dot_size, dot_dist) = prep.calc_size_distance(mat1)\n",
    "# Remove non-dot objects\n",
    "mat1 = prep.select_dots_based_size(mat1, dot_size)\n",
    "# Remove non-elliptical objects\n",
    "mat1 = prep.select_dots_based_ratio(mat1)\n",
    "losa.save_image(outputs_path + \"/segmented_dots.jpg\", mat1) # Save image for checking\n",
    "# Calculate the slopes of horizontal lines and vertical lines.\n",
    "hor_slope = prep.calc_hor_slope(mat1)\n",
    "ver_slope = prep.calc_ver_slope(mat1)\n",
    "\n",
    "# Group points to horizontal lines\n",
    "list_hor_lines = prep.group_dots_hor_lines(mat1, hor_slope, dot_dist)\n",
    "list_ver_lines = prep.group_dots_ver_lines(mat1, ver_slope, dot_dist)\n",
    "list_hor_lines = prep.remove_residual_dots_hor(list_hor_lines, hor_slope)\n",
    "list_ver_lines = prep.remove_residual_dots_ver(list_ver_lines, ver_slope)\n",
    "# Save output for checking\n",
    "losa.save_plot_image(outputs_path + \"/horizontal_lines.png\", list_hor_lines, height, width)\n",
    "losa.save_plot_image(outputs_path + \"/vertical_lines.png\", list_ver_lines, height, width)\n",
    "\n",
    "\n",
    "list_hor_data = post.calc_residual_hor(list_hor_lines, 0.0, 0.0)\n",
    "list_ver_data = post.calc_residual_ver(list_ver_lines, 0.0, 0.0)\n",
    "losa.save_residual_plot(outputs_path + \"/hor_residual_before_correction.png\",\n",
    "                      list_hor_data, height, width)\n",
    "losa.save_residual_plot(outputs_path + \"/ver_residual_before_correction.png\",\n",
    "                      list_ver_data, height, width)\n",
    "\n",
    "# Calculate the center of distortion\n",
    "(xcenter, ycenter) = proc.find_cod_coarse(list_hor_lines, list_ver_lines)\n",
    "# Calculate coefficients of the correction model\n",
    "list_fact_bw = proc.calc_coef_backward(list_hor_lines, list_ver_lines,\n",
    "                                    xcenter, ycenter, poly_coef)\n",
    "# Save the results for later use.\n",
    "losa.save_metadata_txt(outputs_path + \"/coefficients_radial_distortion_backward.txt\",\n",
    "                     xcenter, ycenter, list_fact_bw)\n",
    "\n",
    "\n",
    "# Calculate coefficients of the correction model\n",
    "list_fact_fw = proc.calc_coef_forward(list_hor_lines, list_ver_lines,\n",
    "                                    xcenter, ycenter, poly_coef)\n",
    "losa.save_metadata_txt(outputs_path + \"/coefficients_radial_distortion_forward.txt\",\n",
    "                     xcenter, ycenter, list_fact_fw)\n",
    "\n",
    "# Load coefficients from previous calculation if need to\n",
    "# (xcenter, ycenter, list_fact) = losa.load_metadata_txt(\n",
    "#     outputs_path + \"/coefficients_radial_distortion.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af60c71",
   "metadata": {},
   "source": [
    "## Correct the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b255003",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = losa.load_image(distortion_measurment_path) # Load raw image\n",
    "corrected_mat = post.unwarp_image_backward(mat1.astype(np.uint8), xcenter, ycenter, list_fact_bw)\n",
    "losa.save_image(outputs_path + \"/corrected_image.png\", corrected_mat)\n",
    "losa.save_image(outputs_path + \"/difference.png\", corrected_mat - mat1)\n",
    "\n",
    "# # Decorrect the image\n",
    "# mat2 = losa.load_image('outputs/corrected_image.png') # Load corrected image\n",
    "# decorrected_mat = post.unwarp_image_backward(mat2.astype(np.uint8), xcenter, ycenter, list_fact_fw)\n",
    "# losa.save_image(outputs_path + \"/decorrected_image.png\", decorrected_mat)\n",
    "# losa.save_image(outputs_path + \"/decor_difference.png\", decorrected_mat - mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d7180",
   "metadata": {},
   "source": [
    "## Dot detection mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f039ff",
   "metadata": {},
   "source": [
    "### Finding the center of the markers in the corrected and raw FoV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425fd044",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not PREFERRED_METHOD:\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    marker_halfsize = 20\n",
    "    # Load image (grayscale or binary)\n",
    "    img = cv2.imread(outputs_path + \"/corrected_image.png\", cv2.IMREAD_GRAYSCALE)\n",
    "    # Threshold the image (you can tweak threshold value or use adaptive/otsu)\n",
    "    _, binary = cv2.threshold(img, 70, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Invert if needed (dots should be white on black background)\n",
    "    if INVERT:\n",
    "        binary = cv2.bitwise_not(binary)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    centroids_c = []\n",
    "    # Loop through each detected contour (dot)\n",
    "    for cnt in contours:\n",
    "        M = cv2.moments(cnt)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = M[\"m10\"] / M[\"m00\"]\n",
    "            cy = M[\"m01\"] / M[\"m00\"]\n",
    "            centroids_c.append((cx, cy))\n",
    "    centroids_c = np.array(centroids_c)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    output = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    i = 0\n",
    "    for (x, y) in centroids_c:\n",
    "        cv2.rectangle(output,(int(x-marker_halfsize),int(y-marker_halfsize)),(int(x+marker_halfsize),int(y+marker_halfsize)),(0,255,0),3)\n",
    "        cv2.putText(output,str(i),(int(x),int(y)), font, 2,(0,255,0),4,cv2.LINE_AA)\n",
    "        i+=1\n",
    "    cv2.imwrite(outputs_path+'/annoted_corrected_image.png', output)\n",
    "    # cv2.namedWindow('Centroids markers', cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.imshow(\"Centroids markers\", output)\n",
    "    # cv2.resizeWindow('Centroids markers', 400, 400)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    # Do the same or the raw image\n",
    "    img = cv2.imread(distortion_measurment_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Threshold the image (you can tweak threshold value or use adaptive/otsu)\n",
    "    _, binary = cv2.threshold(img, 70, 255, cv2.THRESH_BINARY)\n",
    "    # Invert if needed (dots should be white on black background)\n",
    "    if INVERT:\n",
    "        binary = cv2.bitwise_not(binary)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    centroids_r = []\n",
    "    # Loop through each detected contour (dot)\n",
    "    for cnt in contours:\n",
    "        M = cv2.moments(cnt)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = M[\"m10\"] / M[\"m00\"]\n",
    "            cy = M[\"m01\"] / M[\"m00\"]\n",
    "            centroids_r.append((cx, cy))\n",
    "    centroids_r = np.array(centroids_r)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    output = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    i = 0\n",
    "    for (x, y) in centroids_r:\n",
    "        cv2.rectangle(output,(int(x-marker_halfsize),int(y-marker_halfsize)),(int(x+marker_halfsize),int(y+marker_halfsize)),(0,255,0),3)\n",
    "        cv2.putText(output,str(i),(int(x),int(y)), font, 2,(0,255,0),4,cv2.LINE_AA)\n",
    "        i+=1\n",
    "    cv2.imwrite(outputs_path+'/annoted_raw_image.png', output)\n",
    "    # cv2.namedWindow('Centroids markers', cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.imshow(\"Centroids markers\", output)\n",
    "    # cv2.resizeWindow('Centroids markers', 400, 400)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76807231",
   "metadata": {},
   "source": [
    "### Remove some points if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb328ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not PREFERRED_METHOD:\n",
    "    print(centroids_r.shape)\n",
    "    centroids_r = np.delete(centroids_r,0,axis =0)\n",
    "    print(centroids_r.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8086b2d",
   "metadata": {},
   "source": [
    "### Computing the distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not PREFERRED_METHOD:\n",
    "      import pandas as pd\n",
    "      \n",
    "      if centroids_c.shape != centroids_r.shape:\n",
    "            raise ValueError(\"Not all centroids were found in one of the image. Remove the correct one.\")\n",
    "      \n",
    "      h = ((centroids_r[:,0]-image_fov_x/2)**2 + (centroids_r[:,1]-image_fov_y/2)**2)**.5\n",
    "      h0 = ((centroids_c[:,0]-image_fov_x/2)**2 + (centroids_c[:,1]-image_fov_y/2)**2)**.5\n",
    "      distortion = 100*(h-h0)/h0\n",
    "\n",
    "      ###########################################\n",
    "      middle_point = distortion.shape[0]//2-1\n",
    "      ###########################################\n",
    "\n",
    "      fov = np.linspace(0,1,distortion.shape[0]-middle_point)\n",
    "      formatted_data = pd.DataFrame({'Normalized FoV': fov,'distortion [%]': distortion[middle_point:]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb95eee",
   "metadata": {},
   "source": [
    "## Dot prediction mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def24e96",
   "metadata": {},
   "source": [
    "### Compute the distorted position and relative distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabd01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREFERRED_METHOD:\n",
    "    import pandas as pd\n",
    "    (xcenter, ycenter, list_fact) = losa.load_metadata_txt(outputs_path + \"/coefficients_radial_distortion_forward.txt\")\n",
    "    center_delta = ((xcenter-image_fov_x/2)**2 + (ycenter-image_fov_y/2)**2)**.5\n",
    "    radial_fov = (image_fov_x**2+image_fov_y**2)**.5\n",
    "    print('Radial difference between the sidtortion center and Fov center:',center_delta,'px (',100*center_delta/(radial_fov/2),'%)')\n",
    "    distortion = []\n",
    "    for i in range(preferred_method_dots):\n",
    "        x = np.linspace(image_fov_x/2,image_fov_x,preferred_method_dots)\n",
    "        y = np.linspace(image_fov_y/2,image_fov_y,preferred_method_dots)\n",
    "        [xd, yd] = utils.find_point_to_point((x[i],y[i]), xcenter, ycenter, list_fact_fw, output_order='xy')\n",
    "\n",
    "        h = (xd**2 + yd**2)**.5\n",
    "        h0 = (x[i]**2 + y[i]**2)**.5\n",
    "        distortion.append(100*(h-h0)/h0)\n",
    "\n",
    "    distortion = np.array(distortion)\n",
    "    fov = np.linspace(0,1,preferred_method_dots)\n",
    "    formatted_data = pd.DataFrame({'Normalized FoV': fov,'distortion [%]': distortion})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ec735",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e03f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fov 0 should have close to 0% distortion. If not, check the middle point computation or make sure the distortion and fov centers are meant to not be confounded')\n",
    "print(formatted_data)\n",
    "formatted_data.to_csv(outputs_path+'/distortion.txt', index=False, sep=',', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
